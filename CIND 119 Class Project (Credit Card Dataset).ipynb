{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0232f0fb",
   "metadata": {},
   "source": [
    "# Phase 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a786a",
   "metadata": {},
   "source": [
    "# Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fcc4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Creditability  Account Balance  Duration of Credit (month)  \\\n",
      "0              1                1                          18   \n",
      "1              1                1                           9   \n",
      "2              1                2                          12   \n",
      "3              1                1                          12   \n",
      "4              1                1                          12   \n",
      "\n",
      "   Payment Status of Previous Credit  Purpose  Credit Amount  \\\n",
      "0                                  4        2           1049   \n",
      "1                                  4        0           2799   \n",
      "2                                  2        9            841   \n",
      "3                                  4        0           2122   \n",
      "4                                  4        0           2171   \n",
      "\n",
      "   Value Savings/Stocks  Length of current employment  Instalment per cent  \\\n",
      "0                     1                             2                    4   \n",
      "1                     1                             3                    2   \n",
      "2                     2                             4                    2   \n",
      "3                     1                             3                    3   \n",
      "4                     1                             3                    4   \n",
      "\n",
      "   Sex & Marital Status  ...  Duration in Current address  \\\n",
      "0                     2  ...                            4   \n",
      "1                     3  ...                            2   \n",
      "2                     2  ...                            4   \n",
      "3                     3  ...                            2   \n",
      "4                     3  ...                            4   \n",
      "\n",
      "   Most valuable available asset  Age (years)  Concurrent Credits  \\\n",
      "0                              2           21                   3   \n",
      "1                              1           36                   3   \n",
      "2                              1           23                   3   \n",
      "3                              1           39                   3   \n",
      "4                              2           38                   1   \n",
      "\n",
      "   Type of apartment  No of Credits at this Bank  Occupation  \\\n",
      "0                  1                           1           3   \n",
      "1                  1                           2           3   \n",
      "2                  1                           1           2   \n",
      "3                  1                           2           2   \n",
      "4                  2                           2           2   \n",
      "\n",
      "   No of dependents  Telephone  Foreign Worker  \n",
      "0                 1          1               1  \n",
      "1                 2          1               1  \n",
      "2                 1          1               1  \n",
      "3                 2          1               2  \n",
      "4                 1          1               2  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Credit Card Dataset\n",
    "url = \"./project_datasets/german_credit_card/german_credit.csv\"  # Replace with the actual URL or file path\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00195c",
   "metadata": {},
   "source": [
    "# Step 2: Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193490f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                             Non-Null Count  Dtype\n",
      "---  ------                             --------------  -----\n",
      " 0   Creditability                      1000 non-null   int64\n",
      " 1   Account Balance                    1000 non-null   int64\n",
      " 2   Duration of Credit (month)         1000 non-null   int64\n",
      " 3   Payment Status of Previous Credit  1000 non-null   int64\n",
      " 4   Purpose                            1000 non-null   int64\n",
      " 5   Credit Amount                      1000 non-null   int64\n",
      " 6   Value Savings/Stocks               1000 non-null   int64\n",
      " 7   Length of current employment       1000 non-null   int64\n",
      " 8   Instalment per cent                1000 non-null   int64\n",
      " 9   Sex & Marital Status               1000 non-null   int64\n",
      " 10  Guarantors                         1000 non-null   int64\n",
      " 11  Duration in Current address        1000 non-null   int64\n",
      " 12  Most valuable available asset      1000 non-null   int64\n",
      " 13  Age (years)                        1000 non-null   int64\n",
      " 14  Concurrent Credits                 1000 non-null   int64\n",
      " 15  Type of apartment                  1000 non-null   int64\n",
      " 16  No of Credits at this Bank         1000 non-null   int64\n",
      " 17  Occupation                         1000 non-null   int64\n",
      " 18  No of dependents                   1000 non-null   int64\n",
      " 19  Telephone                          1000 non-null   int64\n",
      " 20  Foreign Worker                     1000 non-null   int64\n",
      "dtypes: int64(21)\n",
      "memory usage: 164.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d703fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Creditability  Account Balance  Duration of Credit (month)  \\\n",
      "count    1000.000000      1000.000000                 1000.000000   \n",
      "mean        0.700000         2.577000                   20.903000   \n",
      "std         0.458487         1.257638                   12.058814   \n",
      "min         0.000000         1.000000                    4.000000   \n",
      "25%         0.000000         1.000000                   12.000000   \n",
      "50%         1.000000         2.000000                   18.000000   \n",
      "75%         1.000000         4.000000                   24.000000   \n",
      "max         1.000000         4.000000                   72.000000   \n",
      "\n",
      "       Payment Status of Previous Credit      Purpose  Credit Amount  \\\n",
      "count                         1000.00000  1000.000000     1000.00000   \n",
      "mean                             2.54500     2.828000     3271.24800   \n",
      "std                              1.08312     2.744439     2822.75176   \n",
      "min                              0.00000     0.000000      250.00000   \n",
      "25%                              2.00000     1.000000     1365.50000   \n",
      "50%                              2.00000     2.000000     2319.50000   \n",
      "75%                              4.00000     3.000000     3972.25000   \n",
      "max                              4.00000    10.000000    18424.00000   \n",
      "\n",
      "       Value Savings/Stocks  Length of current employment  \\\n",
      "count           1000.000000                   1000.000000   \n",
      "mean               2.105000                      3.384000   \n",
      "std                1.580023                      1.208306   \n",
      "min                1.000000                      1.000000   \n",
      "25%                1.000000                      3.000000   \n",
      "50%                1.000000                      3.000000   \n",
      "75%                3.000000                      5.000000   \n",
      "max                5.000000                      5.000000   \n",
      "\n",
      "       Instalment per cent  Sex & Marital Status  ...  \\\n",
      "count          1000.000000            1000.00000  ...   \n",
      "mean              2.973000               2.68200  ...   \n",
      "std               1.118715               0.70808  ...   \n",
      "min               1.000000               1.00000  ...   \n",
      "25%               2.000000               2.00000  ...   \n",
      "50%               3.000000               3.00000  ...   \n",
      "75%               4.000000               3.00000  ...   \n",
      "max               4.000000               4.00000  ...   \n",
      "\n",
      "       Duration in Current address  Most valuable available asset  \\\n",
      "count                  1000.000000                    1000.000000   \n",
      "mean                      2.845000                       2.358000   \n",
      "std                       1.103718                       1.050209   \n",
      "min                       1.000000                       1.000000   \n",
      "25%                       2.000000                       1.000000   \n",
      "50%                       3.000000                       2.000000   \n",
      "75%                       4.000000                       3.000000   \n",
      "max                       4.000000                       4.000000   \n",
      "\n",
      "       Age (years)  Concurrent Credits  Type of apartment  \\\n",
      "count   1000.00000         1000.000000        1000.000000   \n",
      "mean      35.54200            2.675000           1.928000   \n",
      "std       11.35267            0.705601           0.530186   \n",
      "min       19.00000            1.000000           1.000000   \n",
      "25%       27.00000            3.000000           2.000000   \n",
      "50%       33.00000            3.000000           2.000000   \n",
      "75%       42.00000            3.000000           2.000000   \n",
      "max       75.00000            3.000000           3.000000   \n",
      "\n",
      "       No of Credits at this Bank   Occupation  No of dependents    Telephone  \\\n",
      "count                 1000.000000  1000.000000       1000.000000  1000.000000   \n",
      "mean                     1.407000     2.904000          1.155000     1.404000   \n",
      "std                      0.577654     0.653614          0.362086     0.490943   \n",
      "min                      1.000000     1.000000          1.000000     1.000000   \n",
      "25%                      1.000000     3.000000          1.000000     1.000000   \n",
      "50%                      1.000000     3.000000          1.000000     1.000000   \n",
      "75%                      2.000000     3.000000          1.000000     2.000000   \n",
      "max                      4.000000     4.000000          2.000000     2.000000   \n",
      "\n",
      "       Foreign Worker  \n",
      "count     1000.000000  \n",
      "mean         1.037000  \n",
      "std          0.188856  \n",
      "min          1.000000  \n",
      "25%          1.000000  \n",
      "50%          1.000000  \n",
      "75%          1.000000  \n",
      "max          2.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics for numerical attributes\n",
    "summary_stats = data.describe()\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d4720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    700\n",
      "0    300\n",
      "Name: Creditability, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore the distribution of the class attribute\n",
    "class_distribution = data['Creditability'].value_counts()\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d60d7",
   "metadata": {},
   "source": [
    "# Step 3: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b1a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
    "data = data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a489dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns and numerical columns\n",
    "categorical_columns = ['Account Balance', 'Payment Status of Previous Credit', 'Purpose', 'Concurrent Credits', 'Length of current employment', 'Sex & Marital Status', 'Guarantors', 'Duration in Current address', 'Most valuable available asset', 'Type of apartment', 'No of Credits at this Bank', 'Occupation', 'No of dependents', 'Telephone', 'Foreign Worker']\n",
    "numerical_columns = ['Duration of Credit (month)', 'Credit Amount', 'Value Savings/Stocks', 'Instalment per cent', 'Age (years)']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8d6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical attributes into numerical format\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "encoded_features = encoder.fit_transform(data[categorical_columns])\n",
    "encoded_columns = encoder.get_feature_names_out(categorical_columns)\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeca70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical attributes\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data[numerical_columns])\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=numerical_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "999d23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate encoded and scaled dataframes\n",
    "preprocessed_data = pd.concat([encoded_df, scaled_df, data['Creditability']], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1761b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = preprocessed_data.drop('Creditability', axis=1)\n",
    "y = preprocessed_data['Creditability']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479631aa",
   "metadata": {},
   "source": [
    "# Phase 2: Predictive Modeling - Decision Tree and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd28ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Import Necessary Libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc679f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Split the Data into Train and Test Sets\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f72671ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  Step 3: Train Decision Tree Classifier\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "decision_tree_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77243a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Step 4: Make Predictions using Decision Tree\n",
    "\n",
    "# Make predictions on the test data\n",
    "decision_tree_predictions = decision_tree_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65f98d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.72\n",
      "Decision Tree Confusion Matrix:\n",
      " [[ 33  29]\n",
      " [ 27 111]]\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54        62\n",
      "           1       0.79      0.80      0.80       138\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.72      0.72      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Step 5: Evaluate Decision Tree Model\n",
    "\n",
    "# Calculate accuracy\n",
    "decision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "decision_tree_confusion_matrix = confusion_matrix(y_test, decision_tree_predictions)\n",
    "decision_tree_classification_report = classification_report(y_test, decision_tree_predictions)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", decision_tree_accuracy)\n",
    "print(\"Decision Tree Confusion Matrix:\\n\", decision_tree_confusion_matrix)\n",
    "print(\"Decision Tree Classification Report:\\n\", decision_tree_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5937d3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 6: Train Naive Bayes Classifier\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "naive_bayes_model = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "naive_bayes_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d78a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7: Make Predictions using Naive Bayes\n",
    "\n",
    "# Make predictions on the test data\n",
    "naive_bayes_predictions = naive_bayes_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abe25856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.65\n",
      "Naive Bayes Confusion Matrix:\n",
      " [[32 30]\n",
      " [40 98]]\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.52      0.48        62\n",
      "           1       0.77      0.71      0.74       138\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.61      0.61      0.61       200\n",
      "weighted avg       0.67      0.65      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Step 8: Evaluate Naive Bayes Model\n",
    "    \n",
    "# Calculate accuracy\n",
    "naive_bayes_accuracy = accuracy_score(y_test, naive_bayes_predictions)\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "naive_bayes_confusion_matrix = confusion_matrix(y_test, naive_bayes_predictions)\n",
    "naive_bayes_classification_report = classification_report(y_test, naive_bayes_predictions)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", naive_bayes_accuracy)\n",
    "print(\"Naive Bayes Confusion Matrix:\\n\", naive_bayes_confusion_matrix)\n",
    "print(\"Naive Bayes Classification Report:\\n\", naive_bayes_classification_report)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b83ea8",
   "metadata": {},
   "source": [
    "# Phase 3: Compare and Interpret Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28bff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Performing Algorithm: Decision Tree\n",
      "Best Performing Algorithm Accuracy: 0.72\n",
      "Best Performing Algorithm Confusion Matrix:\n",
      " [[ 33  29]\n",
      " [ 27 111]]\n",
      "Best Performing Algorithm Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54        62\n",
      "           1       0.79      0.80      0.80       138\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.72      0.72      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Step 9: Compare Results and Determine Best Performing Algorithm\n",
    "\n",
    "# Compare results and determine the best performing algorithm\n",
    "if decision_tree_accuracy > naive_bayes_accuracy:\n",
    "    best_algorithm = \"Decision Tree\"\n",
    "    best_predictions = decision_tree_predictions\n",
    "else:\n",
    "    best_algorithm = \"Naive Bayes\"\n",
    "    best_predictions = naive_bayes_predictions\n",
    "\n",
    "# Print the best performing algorithm\n",
    "print(\"Best Performing Algorithm:\", best_algorithm)\n",
    "\n",
    "# Calculate accuracy for the best performing algorithm\n",
    "best_accuracy = accuracy_score(y_test, best_predictions)\n",
    "print(\"Best Performing Algorithm Accuracy:\", best_accuracy)\n",
    "\n",
    "# Print confusion matrix and classification report for the best performing algorithm\n",
    "best_confusion_matrix = confusion_matrix(y_test, best_predictions)\n",
    "best_classification_report = classification_report(y_test, best_predictions)\n",
    "\n",
    "print(\"Best Performing Algorithm Confusion Matrix:\\n\", best_confusion_matrix)\n",
    "print(\"Best Performing Algorithm Classification Report:\\n\", best_classification_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354aa35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b906187a",
   "metadata": {},
   "source": [
    "# Phase 4: Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "468165d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Conclusions ###\n",
      "\n",
      "During the course of this project, our team undertook an extensive analysis of the Credit Card Dataset to predict creditability and devise an effective data analytics strategy for the bank's loan approval process. The following key conclusions were drawn from our analysis:\n",
      "\n",
      "1. Data Preparation and Preprocessing:\n",
      "We performed thorough data preparation, which included handling missing values, encoding categorical attributes, and scaling numerical features. This process ensured that the dataset was suitable for training machine learning models.\n",
      "\n",
      "2. Predictive Modeling:\n",
      "We employed two classification algorithms, Decision Tree and Naive Bayes, to predict the creditability of loan applicants. Both models demonstrated reasonably accurate predictions, with Decision Tree achieving an accuracy of 0.72 and Naive Bayes achieving an accuracy of 0.65 .\n",
      "\n",
      "3. Model Comparison:\n",
      "By comparing the results of the two algorithms, we identified that the Decision Tree model outperformed Naive Bayes in terms of overall accuracy and the ability to correctly classify applicants' creditability. The best performing algorithm was found to be Decision Tree with an accuracy of 0.72 .\n",
      "\n",
      "4. Interpretability:\n",
      "The Decision Tree model allowed for the interpretation of the decision-making process through its branching structure, providing insights into the most influential features affecting creditability predictions.\n",
      "\n",
      "### Recommendations ###\n",
      "\n",
      "Based on our analysis and conclusions, we propose the following recommendations for the bank's loan approval strategy:\n",
      "\n",
      "1. Adoption of Decision Tree Model:\n",
      "Given its higher accuracy and better classification performance, we recommend the implementation of the Decision Tree model for predicting creditability. This model can serve as an effective tool to aid loan approval decisions.\n",
      "\n",
      "2. Regular Model Updates:\n",
      "To maintain the model's accuracy and relevance, it's recommended to periodically update it using new data. As the lending landscape evolves, keeping the model up to date ensures that it continues to make accurate predictions.\n",
      "\n",
      "3. Feature Importance Analysis:\n",
      "Further investigation into the feature importance of the Decision Tree model can provide valuable insights into the factors influencing loan approval decisions. This analysis can help the bank refine its lending policies and criteria.\n",
      "\n",
      "4. Additional Data Exploration:\n",
      "Exploring additional external data sources and variables could enhance the predictive power of the model. Variables related to economic indicators, customer behavior, and socio-demographics could potentially contribute to better predictions.\n",
      "\n",
      "5. Deployment and Integration:\n",
      "The bank should consider integrating the Decision Tree model into its loan approval process. It can be used as an initial screening tool to identify applicants with higher creditability, streamlining the decision-making process.\n",
      "\n",
      "In conclusion, the application of data analytics and machine learning techniques can significantly improve the bank's loan approval process. The Decision Tree model, in particular, emerges as a strong contender for predicting creditability accurately. By implementing our recommendations, the bank can optimize its loan approval strategies and make more informed lending decisions.\n"
     ]
    }
   ],
   "source": [
    "# Phase 4: Conclusion and Recommendations\n",
    "\n",
    "# Conclusions\n",
    "print(\"### Conclusions ###\\n\")\n",
    "\n",
    "# Provide a brief summary of the key conclusions drawn from the analysis\n",
    "print(\"During the course of this project, our team undertook an extensive analysis of the Credit Card Dataset to predict creditability and devise an effective data analytics strategy for the bank's loan approval process. The following key conclusions were drawn from our analysis:\\n\")\n",
    "\n",
    "print(\"1. Data Preparation and Preprocessing:\")\n",
    "print(\"We performed thorough data preparation, which included handling missing values, encoding categorical attributes, and scaling numerical features. This process ensured that the dataset was suitable for training machine learning models.\\n\")\n",
    "\n",
    "print(\"2. Predictive Modeling:\")\n",
    "print(\"We employed two classification algorithms, Decision Tree and Naive Bayes, to predict the creditability of loan applicants. Both models demonstrated reasonably accurate predictions, with Decision Tree achieving an accuracy of\", decision_tree_accuracy, \"and Naive Bayes achieving an accuracy of\", naive_bayes_accuracy, \".\\n\")\n",
    "\n",
    "print(\"3. Model Comparison:\")\n",
    "print(\"By comparing the results of the two algorithms, we identified that the Decision Tree model outperformed Naive Bayes in terms of overall accuracy and the ability to correctly classify applicants' creditability. The best performing algorithm was found to be\", best_algorithm, \"with an accuracy of\", best_accuracy, \".\\n\")\n",
    "\n",
    "print(\"4. Interpretability:\")\n",
    "print(\"The Decision Tree model allowed for the interpretation of the decision-making process through its branching structure, providing insights into the most influential features affecting creditability predictions.\\n\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"### Recommendations ###\\n\")\n",
    "\n",
    "# Provide a set of recommendations based on the conclusions\n",
    "print(\"Based on our analysis and conclusions, we propose the following recommendations for the bank's loan approval strategy:\\n\")\n",
    "\n",
    "print(\"1. Adoption of Decision Tree Model:\")\n",
    "print(\"Given its higher accuracy and better classification performance, we recommend the implementation of the Decision Tree model for predicting creditability. This model can serve as an effective tool to aid loan approval decisions.\\n\")\n",
    "\n",
    "print(\"2. Regular Model Updates:\")\n",
    "print(\"To maintain the model's accuracy and relevance, it's recommended to periodically update it using new data. As the lending landscape evolves, keeping the model up to date ensures that it continues to make accurate predictions.\\n\")\n",
    "\n",
    "print(\"3. Feature Importance Analysis:\")\n",
    "print(\"Further investigation into the feature importance of the Decision Tree model can provide valuable insights into the factors influencing loan approval decisions. This analysis can help the bank refine its lending policies and criteria.\\n\")\n",
    "\n",
    "print(\"4. Additional Data Exploration:\")\n",
    "print(\"Exploring additional external data sources and variables could enhance the predictive power of the model. Variables related to economic indicators, customer behavior, and socio-demographics could potentially contribute to better predictions.\\n\")\n",
    "\n",
    "print(\"5. Deployment and Integration:\")\n",
    "print(\"The bank should consider integrating the Decision Tree model into its loan approval process. It can be used as an initial screening tool to identify applicants with higher creditability, streamlining the decision-making process.\\n\")\n",
    "\n",
    "# Concluding remarks\n",
    "print(\"In conclusion, the application of data analytics and machine learning techniques can significantly improve the bank's loan approval process. The Decision Tree model, in particular, emerges as a strong contender for predicting creditability accurately. By implementing our recommendations, the bank can optimize its loan approval strategies and make more informed lending decisions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab736c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
